---
title: "Live AI Agent Infrastructure"
description: "A self-hosted production multi-agent AI system running 24/7 on personal hardware. Outcome-first prompting, hub-and-spoke coordination with a shared blackboard, and a universal agent class with specialist sub-agents for build, design, marketing, security and career. Voice transcription, persistent memory, parallel task execution and proactive monitoring, all through Telegram."
thumbnail: "/assets/ai-infrastructure.jpg"
tags: ["AI", "Multi-Agent", "Docker", "Linux", "Claude", "Whisper", "Python", "Automation", "Infrastructure"]
demoUrl: "/no-demo"
featured: true
---

A production AI system I designed, built and operate on my own hardware. Not a demo. Not a tutorial project. It runs every day, handles real tasks and evolves as my workflow does.

## Problem

AI tools are everywhere but they are stateless, cloud-dependent and context-blind. Every session starts from zero. Every voice message costs API credits. Every task that needs a specialist requires manual handoff. There is no system that just knows your work, stays running and gets things done in parallel.

## Approach

Deployed the agent inside a Docker container on a Debian 12 server (AMD Ryzen 5 3600X, 23GB RAM), isolated, persistent and hardware-controlled. Docker's restart policy keeps it running without babysitting.

Built a local voice pipeline: incoming OGG audio is converted by ffmpeg to 16kHz mono WAV then transcribed by whisper.cpp (tiny model for speed, base model for higher accuracy). Zero external API calls, zero transcription cost.

Designed a file-based memory system: daily markdown logs capture raw session activity while a curated long-term MEMORY.md stores distilled context that persists across restarts and compactions. Raw logging and curated knowledge stay separate to keep context windows efficient.

Implemented outcome-first agent prompting: every spawn brief follows a fixed structure: goal (what we're trying to achieve and why), constraints (hard limits, file paths, what must not change), suggested approach (guidance the agent can deviate from with reason), deliverable (exactly what to produce and where). This eliminates ambiguous hand-offs and produces self-verifying agents.

Built a hub-and-spoke coordination model: the main agent controls all information flow and never executes implementation tasks. Sub-agents append to a shared BLACKBOARD.md on completion; the main agent synthesizes and writes decisions to DECISIONS.md after confirmation. Cross-agent state is always visible and auditable.

Runs a universal agent class: one template, role defined at spawn time. Specialist sub-agents include build/Flutter, design/psychology, marketing, security and career. Spawning parallel specialists from a single template means no architectural overhead when adding new capabilities.

Built a proactive heartbeat system: scheduled checks surface relevant emails, calendar events and project status without needing to be asked. Heartbeat batches periodic checks into single API calls to minimize token usage.

Integrated GitHub workflows with fine-grained PATs scoped per repository: the agent can read all repositories, commit code changes and push to branches autonomously, using the GitHub API for reads and git operations for writes, keeping actions auditable and reversible. Review gates stay in place before merges.

Configured tool access policies per context: read and write for the workspace, browser automation via Playwright (bundled Chromium, no host-level browser dependency) for account and web tasks, exec access for builds and scripts.

## System in Action

The agent operates across four layers simultaneously.

### 1) Voice input, locally processed

Voice messages arrive via Telegram, get transcribed by whisper.cpp on the server and become actionable input in seconds with no cloud dependency.

### 2) Parallel specialist sub-agents
A single instruction can spawn multiple specialists working in parallel: build/Flutter for implementation, design/psychology for UI and behavioral framing, marketing for positioning and outreach, security for threat review, career for job materials. Each completes independently and reports back to the main agent via the shared blackboard.

### 3) Persistent memory across sessions
The agent retains context across every restart. Daily logs capture what happened; long-term memory stores what matters. Starting a new session does not mean starting over.

### 4) Proactive monitoring

Without being prompted, the agent checks email, upcoming calendar events, project build status and active tasks on a schedule, surfacing what needs attention before it becomes urgent.

## Results

Voice messages transcribed locally in under 5 seconds with zero API cost.

Specialist sub-agents complete parallel implementation, research, design and content tasks simultaneously from a single universal template.

Full context retained across sessions and server restarts.

GitHub commits and branch pushes executed autonomously within approved workflows: reads via API, writes via git, fully auditable.

Proactive monitoring surfaces calendar events, emails and project status without prompting.

Flutter app (StreakUp â€“ Habit Tracker & Goals): published on Google Play, 701 automated tests written and validated, with RevenueCat monetization, AdMob integration and a 12-member international beta team.

System running continuously since deployment.

## Tech Stack

Hardware: Debian 12, AMD Ryzen 5 3600X, 23GB RAM, self-hosted

Container: Docker (isolated runtime, persistent volume mounts, auto-restart policy)

AI Reasoning: Claude Sonnet and Opus via Anthropic API

Voice: whisper.cpp (local STT, tiny model default / base model for accuracy) and ffmpeg (audio pipeline)

Memory: Markdown-based daily logs and curated long-term memory file, version-controlled alongside the workspace

Automation: Bash, Node.js, Python, GitHub API, fine-grained PATs (least-privilege, scoped per repository)

Browser Automation: Playwright with bundled Chromium (no host-level browser dependency)

Interface: Telegram bot integration
